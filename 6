irise_llama-irise_llama-1  |     hf_raise_for_status(r)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/utils/_errors.py", line 277, in hf_raise_for_status
irise_llama-irise_llama-1  |     raise GatedRepoError(message, response) from e
irise_llama-irise_llama-1  | huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-66b0e7cb-767d40cd5cae492e4af9c95d;7c71f6f6-1727-4c75-beb5-2e7bde2d55e1)
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json.
irise_llama-irise_llama-1  | Access to model meta-llama/Meta-Llama-3-8B is restricted. You must be authenticated to access it.
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | During handling of the above exception, another exception occurred:
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | Traceback (most recent call last):
irise_llama-irise_llama-1  |   File "/usr/local/bin/uvicorn", line 8, in <module>
irise_llama-irise_llama-1  |     sys.exit(main())
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1157, in __call__
irise_llama-irise_llama-1  |     return self.main(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1078, in main
irise_llama-irise_llama-1  |     rv = self.invoke(ctx)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1434, in invoke
irise_llama-irise_llama-1  |     return ctx.invoke(self.callback, **ctx.params)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 783, in invoke
irise_llama-irise_llama-1  |     return __callback(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/main.py", line 449, in main
irise_llama-irise_llama-1  |     h11_max_incomplete_event_size=h11_max_incomplete_event_size,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/main.py", line 569, in run
irise_llama-irise_llama-1  |     server.run()
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/server.py", line 60, in run
irise_llama-irise_llama-1  |     return asyncio.run(self.serve(sockets=sockets))
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/asyncio/runners.py", line 43, in run
irise_llama-irise_llama-1  |     return loop.run_until_complete(main)
irise_llama-irise_llama-1  |   File "uvloop/loop.pyx", line 1517, in uvloop.loop.Loop.run_until_complete
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/server.py", line 67, in serve
irise_llama-irise_llama-1  |     config.load()
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/config.py", line 477, in load
irise_llama-irise_llama-1  |     self.loaded_app = import_from_string(self.app)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/importer.py", line 21, in import_from_string
irise_llama-irise_llama-1  |     module = importlib.import_module(module_str)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
irise_llama-irise_llama-1  |     return _bootstrap._gcd_import(name[level:], package, level)
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
irise_llama-irise_llama-1  |   File "./app.py", line 31, in <module>
irise_llama-irise_llama-1  |     tokenizer = AutoTokenizer.from_pretrained(model,token = "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")
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 643, in from_pretrained
irise_llama-irise_llama-1  |     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 500, in get_tokenizer_config
irise_llama-irise_llama-1  |     _commit_hash=commit_hash,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/utils/hub.py", line 434, in cached_file
irise_llama-irise_llama-1  |     f"{path_or_repo_id} is not a local folder and is not a valid model identifier "
irise_llama-irise_llama-1  | OSError: meta-llama/Meta-Llama-3-8B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
irise_llama-irise_llama-1  | If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.
irise_llama-irise_llama-1  | Traceback (most recent call last):
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/utils/_errors.py", line 261, in hf_raise_for_status
irise_llama-irise_llama-1  |     response.raise_for_status()
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/requests/models.py", line 1021, in raise_for_status
irise_llama-irise_llama-1  |     raise HTTPError(http_error_msg, response=self)
irise_llama-irise_llama-1  | requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | The above exception was the direct cause of the following exception:
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | Traceback (most recent call last):
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/utils/hub.py", line 429, in cached_file
irise_llama-irise_llama-1  |     local_files_only=local_files_only,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
irise_llama-irise_llama-1  |     return fn(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/file_download.py", line 1199, in hf_hub_download
irise_llama-irise_llama-1  |     timeout=etag_timeout,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
irise_llama-irise_llama-1  |     return fn(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/file_download.py", line 1541, in get_hf_file_metadata
irise_llama-irise_llama-1  |     hf_raise_for_status(r)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/huggingface_hub/utils/_errors.py", line 277, in hf_raise_for_status
irise_llama-irise_llama-1  |     raise GatedRepoError(message, response) from e
irise_llama-irise_llama-1  | huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-66b0e7d6-3d1e046002f7152b3ee10021;3b0d880b-4f44-4a02-aaf3-9cb65fd9ccec)
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json.
irise_llama-irise_llama-1  | Access to model meta-llama/Meta-Llama-3-8B is restricted. You must be authenticated to access it.
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | During handling of the above exception, another exception occurred:
irise_llama-irise_llama-1  | 
irise_llama-irise_llama-1  | Traceback (most recent call last):
irise_llama-irise_llama-1  |   File "/usr/local/bin/uvicorn", line 8, in <module>
irise_llama-irise_llama-1  |     sys.exit(main())
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1157, in __call__
irise_llama-irise_llama-1  |     return self.main(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1078, in main
irise_llama-irise_llama-1  |     rv = self.invoke(ctx)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 1434, in invoke
irise_llama-irise_llama-1  |     return ctx.invoke(self.callback, **ctx.params)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/click/core.py", line 783, in invoke
irise_llama-irise_llama-1  |     return __callback(*args, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/main.py", line 449, in main
irise_llama-irise_llama-1  |     h11_max_incomplete_event_size=h11_max_incomplete_event_size,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/main.py", line 569, in run
irise_llama-irise_llama-1  |     server.run()
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/server.py", line 60, in run
irise_llama-irise_llama-1  |     return asyncio.run(self.serve(sockets=sockets))
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/asyncio/runners.py", line 43, in run
irise_llama-irise_llama-1  |     return loop.run_until_complete(main)
irise_llama-irise_llama-1  |   File "uvloop/loop.pyx", line 1517, in uvloop.loop.Loop.run_until_complete
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/server.py", line 67, in serve
irise_llama-irise_llama-1  |     config.load()
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/config.py", line 477, in load
irise_llama-irise_llama-1  |     self.loaded_app = import_from_string(self.app)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/uvicorn/importer.py", line 21, in import_from_string
irise_llama-irise_llama-1  |     module = importlib.import_module(module_str)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
irise_llama-irise_llama-1  |     return _bootstrap._gcd_import(name[level:], package, level)
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
irise_llama-irise_llama-1  |   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
irise_llama-irise_llama-1  |   File "./app.py", line 31, in <module>
irise_llama-irise_llama-1  |     tokenizer = AutoTokenizer.from_pretrained(model,token = "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")
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 643, in from_pretrained
irise_llama-irise_llama-1  |     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 500, in get_tokenizer_config
irise_llama-irise_llama-1  |     _commit_hash=commit_hash,
irise_llama-irise_llama-1  |   File "/usr/local/lib/python3.7/site-packages/transformers/utils/hub.py", line 434, in cached_file
irise_llama-irise_llama-1  |     f"{path_or_repo_id} is not a local folder and is not a valid model identifier "
irise_llama-irise_llama-1  | OSError: meta-llama/Meta-Llama-3-8B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
irise_llama-irise_llama-1  | If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.
irise_llama-irise_llama-1 exited with code 1
^Ccanceled
root@opexwise-ml3:/home/balasubramaniyan.d/irise_llama# 

